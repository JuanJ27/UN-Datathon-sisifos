{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa70cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install gensim\n",
    "!pip install imblearn\n",
    "!pip install contractions\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d57fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01 a series of steps to be carried out or goals to be accomplished\n",
      "program.n.02 a system of projects or services intended to meet a public need\n",
      "broadcast.n.02 a radio or television show\n",
      "platform.n.02 a document stating the aims and principles of a political party\n",
      "program.n.05 an announcement of the events that will occur as part of a theatrical or sporting event\n",
      "course_of_study.n.01 an integrated course of academic studies\n",
      "program.n.07 (computer science) a sequence of instructions that a computer can interpret and execute\n",
      "program.n.08 a performance (or series of performances) at a public presentation\n",
      "program.v.01 arrange a program of or for\n",
      "program.v.02 write a computer program\n"
     ]
    }
   ],
   "source": [
    "# load dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "#import fasttext\n",
    "#import fasttext.util\n",
    "#ft = fasttext.load_model('cc.es.300.bin') # load fasttext model\n",
    "import gensim\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Télécharger les ressources NLTK nécessaires\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Maintenant, vous pouvez utiliser wordnet\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"program\")\n",
    "for syn in syns:\n",
    "    print(syn.name(), syn.definition())\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33985215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 18:47:22.851831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731350842.870909   19445 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731350842.876396   19445 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-11 18:47:22.896133: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2024-11-11 18:47:48.014958: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: a9148037-4152-5dcd-941e-df9b12c7fc46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Mi jefe me hizo insinuaciones sexuales incómodas en la oficina, y nadie me escucha cuando trato de denunciarlo.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: 94027de6-cec6-5b05-b512-224a9d507a8e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Un hombre en el transporte público intentó tocarme de manera inapropiada, fue muy intimidante y me siento insegura.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: 376501e8-b193-5d94-addf-5e44e205ec1f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Mi pareja me empujó y me golpeó en una discusión, y temo que pueda pasar de nuevo.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: fb48d1b8-81d1-53e3-ab80-8e14d2476268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Fui acosada sexualmente por un compañero de trabajo, que siempre hace comentarios sobre mi cuerpo.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: 30c794dd-3a80-5c8a-a87e-cb7169160d01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Mi esposo controla todos los gastos y no me deja acceder a nuestro dinero, ni siquiera para comprar cosas básicas.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: 35dba6e6-f98a-5dc0-b3e4-f94aaa1c0c4b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Un hombre en el trabajo intentó besarme a la fuerza y luego me amenazó con despedirme si contaba algo.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Published alert with Message ID: 7474e2d2-1fc6-520a-a429-bd7e4c509381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert sent for comment: Mis padres constantemente me critican y hacen que dude de mis capacidades, haciéndome sentir inferior.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import logging\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "from io import StringIO\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "# import contractions\n",
    "# from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Set up logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class S3Handler:\n",
    "    \"\"\"Handles interactions with S3.\"\"\"\n",
    "    \n",
    "    def __init__(self, bucket_name):\n",
    "        self.s3 = boto3.client('s3')\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def load_text_from_s3(self, key):\n",
    "        \"\"\"Loads text file from S3 and returns a list of comments.\"\"\"\n",
    "        obj = self.s3.get_object(Bucket=self.bucket_name, Key=key)\n",
    "        text_data = obj['Body'].read().decode('utf-8')\n",
    "        comments = text_data.strip().splitlines()\n",
    "        return comments\n",
    "\n",
    "    def load_model_from_s3(self, key):\n",
    "        obj = self.s3.get_object(Bucket=self.bucket_name, Key=key)\n",
    "        with open('/tmp/temp_model.h5', 'wb') as f:\n",
    "            f.write(obj['Body'].read())\n",
    "        model = load_model('/tmp/temp_model.h5')\n",
    "        return model\n",
    "\n",
    "    def load_class_weights_from_s3(self, key):\n",
    "        obj = self.s3.get_object(Bucket=self.bucket_name, Key=key)\n",
    "        return pickle.loads(obj['Body'].read())\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"Handles text preprocessing for model input.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_text(text):\n",
    "        text = text.lower()\n",
    "        text = contractions.fix(text)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_text)\n",
    "\n",
    "class GBVAnalyzer:\n",
    "    \"\"\"Analyzes text for indicators of gender-based violence.\"\"\"\n",
    "\n",
    "    def __init__(self, model, class_weights, maxlen=100):\n",
    "        self.model = model\n",
    "        self.class_weights = class_weights\n",
    "        self.tokenizer = Tokenizer(num_words=10000)\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def analyze_comment(self, text):\n",
    "        processed_text = TextPreprocessor.preprocess_text(text)\n",
    "        self.tokenizer.fit_on_texts([processed_text])\n",
    "        sequences = self.tokenizer.texts_to_sequences([processed_text])\n",
    "        X = pad_sequences(sequences, maxlen=self.maxlen)\n",
    "        predictions = self.model.predict(X)\n",
    "        predicted_class = predictions.argmax(axis=-1)\n",
    "        return predicted_class\n",
    "\n",
    "class SnsWrapper:\n",
    "    \"\"\"Encapsulates Amazon SNS topic and subscription functions.\"\"\"\n",
    "\n",
    "    def __init__(self, sns_topic_arn):\n",
    "        self.sns_client = boto3.client(\"sns\")\n",
    "        self.sns_topic_arn = sns_topic_arn\n",
    "\n",
    "    def publish_alert(self, subject, message):\n",
    "        try:\n",
    "            response = self.sns_client.publish(\n",
    "                TopicArn=self.sns_topic_arn,\n",
    "                Subject=subject,\n",
    "                Message=message\n",
    "            )\n",
    "            logger.info(\"Published alert with Message ID: %s\", response['MessageId'])\n",
    "            return response['MessageId']\n",
    "        except ClientError:\n",
    "            logger.exception(\"Failed to send alert.\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Configurations and constants\n",
    "    s3_bucket = 'un-datathon-2024-sisifos'\n",
    "    s3_key_model = 'GBV_Analysis/model/model.h5'\n",
    "    s3_key_class_weights = 'GBV_Analysis/model/class_weights.pickle'\n",
    "    sns_topic_arn = \"arn:aws:sns:us-west-2:080532742200:TweetSentimentAlert\"\n",
    "    s3_key_data = 'GBV_Analysis/comments.txt'\n",
    "    \n",
    "    # Initialize handlers and clients\n",
    "    s3_handler = S3Handler(s3_bucket)\n",
    "    sns_wrapper = SnsWrapper(sns_topic_arn)\n",
    "\n",
    "    # Load GBV detection model and class weights\n",
    "    gbv_model = s3_handler.load_model_from_s3(s3_key_model)\n",
    "    class_weights = s3_handler.load_class_weights_from_s3(s3_key_class_weights)\n",
    "    gbv_analyzer = GBVAnalyzer(gbv_model, class_weights)\n",
    "\n",
    "    # Load comments from the txt file\n",
    "    comments = s3_handler.load_text_from_s3(s3_key_data)\n",
    "\n",
    "    # Process each comment\n",
    "    for comment_text in comments:\n",
    "        prediction = gbv_analyzer.analyze_comment(comment_text)\n",
    "\n",
    "        # If comment is flagged as sexual abuse, send an alert\n",
    "        if prediction == 1:\n",
    "            subject = \"Urgent: Gender-Based Violence Alert\"\n",
    "            message = f\"Alert: A potential case of gender-based violence was detected.\\nMessage: '{comment_text}'\"\n",
    "            sns_wrapper.publish_alert(subject, message)\n",
    "            print(f\"Alert sent for comment: {comment_text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
